{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitbaseconda3b4a6addad404a6182759147affbf3ac",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Spin Glass NADE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dinesh110598/Spinglass_NADE/blob/main/main.ipynb)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.math as tfm\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "If you're running on your local machine, simply download the library.py and TrainingData20k.npy files of the repo to the folder you're running this notebook on."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Colab Instructions\n",
    "Run the following cell if running on Google colaboratory notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl -o library.py https://raw.githubusercontent.com/dinesh110598/Spinglass_NADE/main/library.py\n",
    "#!curl -o TrainingData20k.npy https://raw.githubusercontent.com/dinesh110598/Spinglass_NADE/main/TrainingData20k.npy"
   ]
  },
  {
   "source": [
    "## Brief Introduction\n",
    "We aim to construct a neural network (Neural Autoregressive Distribution Estimator) that can efficiently approximate the Boltzmann distribution of an EA spin glass system in equilibrium via the training data obtained using annealed MCMC simulations. See here for more details: https://arxiv.org/abs/2002.04292\n",
    "\n",
    "The nitty gritty details of the neural network are coded in the library.py whose classes we'll be importing into this notebook directly:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library import NADE_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NADE_orig (inshape=(20,20),num_hidden=20)"
   ]
  },
  {
   "source": [
    "We have performed MCMC simulations of the EA lattice at T=0.5 externally and loading the numpy data for the same into here. Overall, we have 20000 latices of 20x20 EA lattices with Gaussian couplings to train our network with. In order to reduce the memory burden on the neural network, we made sure that *all latices have spins at (0,0) position = 1* and noting that multiplying the entire lattice by -1 gives an energetically equivalent configuration that the neural network need not learn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "t_lattice = np.load ('TrainingData20k.npy')\n",
    "np.all (t_lattice[:,0,0] == 1) #Checks if (0,0) spins=1"
   ]
  },
  {
   "source": [
    "Here, we convert the NumPy array to a tf.data datset so that we can batch and loop over it conveniently while training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices (t_lattice)\n",
    "train_data = train_data.batch(20)"
   ]
  },
  {
   "source": [
    "We'll call train_step method of the NADE_orig class on a sample of the training data. This step builds the \"autograph\" associated with the method to provide significant speedup to subsequent executions of the method"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "loss = model.train_step (tf.constant (t_lattice[0:20,:,:]))\n",
    "tf.print (loss)"
   ]
  },
  {
   "source": [
    "Though we can use fit() method available for keras models, we'll quickly write a custom training loop to keep things transparent and more flexible:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss (for one batch) at step 1: 0.6892\n",
      "20 samples seen so far\n",
      "Training loss (for one batch) at step 21: 0.6900\n",
      "420 samples seen so far\n",
      "Training loss (for one batch) at step 41: 0.6902\n",
      "820 samples seen so far\n",
      "Training loss (for one batch) at step 61: 0.6899\n",
      "1220 samples seen so far\n",
      "Training loss (for one batch) at step 81: 0.6898\n",
      "1620 samples seen so far\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range (epochs):\n",
    "    for step, data in enumerate(train_data):\n",
    "        loss = model.train_step (data)\n",
    "        if step%50 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step+1, float(loss))\n",
    "            )\n",
    "            print(\"%d samples seen so far\" % ((step + 1) * 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
